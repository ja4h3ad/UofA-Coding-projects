{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a25678c9993c1c2bbf0167f2ff03c982",
     "grade": false,
     "grade_id": "header-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tips\n",
    "- To avoid unpleasant surprises, I suggest you _run all cells in their order of appearance_ (__Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "\n",
    "- If the changes you've made to your solution don't seem to be showing up, try running __Kernel__ $\\rightarrow$ __Restart & Run All__ from the menu.\n",
    "\n",
    "\n",
    "- Before submitting your assignment, make sure everything runs as expected. First, restart the kernel (from the menu, select __Kernel__ $\\rightarrow$ __Restart__) and then **run all cells** (from the menu, select __Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "## Reminder\n",
    "\n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, UA email, and collaborators below:\n",
    "\n",
    "\n",
    "\n",
    "Several of the cells in this notebook are **read only** to ensure instructions aren't unintentionally altered.  \n",
    "\n",
    "If you can't edit the cell, it is probably intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Tim Dentry\"\n",
    "# University of Arizona email address\n",
    "EMAIL = \"tdentry@email.arizona.edu\"\n",
    "# Names of any collaborators.  Write N/A if none.\n",
    "COLLABORATORS = \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0783621da2f047c6360f2ec0d56f121c",
     "grade": false,
     "grade_id": "cell-e35b85c2416e40f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Scratchpad\n",
    "\n",
    "You are welcome to create new cells (see the __Cell__ menu) to experiment and debug your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c80ac423030cfa372644d7cd456061af",
     "grade": false,
     "grade_id": "cell-955f8133afe96b26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e07f9ac61f4be6a57b6961cde23a6d58",
     "grade": false,
     "grade_id": "cell-a2292c2fbc4cf52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mini Python tutorial\n",
    "\n",
    "This course uses Python 3.8.\n",
    "\n",
    "Below is a very basic (and incomplete) overview of the Python language... \n",
    "\n",
    "For those completely new to Python, [this section of the official documentation may be useful](https://docs.python.org/3.8/library/stdtypes.html#common-sequence-operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfcd9f827d4855d02514b2e54ba32077",
     "grade": false,
     "grade_id": "cell-d6593132353238c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "[2, 3, 4, 5]\n",
      "[2]\n",
      "hello, Josuke!\n",
      "Howdy, partner!\n",
      "13\n",
      "Hi, Fred!\n",
      "[('radical', 4), ('analysis', 7), ('bighorn', 12), ('bounce', 32)]\n",
      "[('analysis', 7), ('bighorn', 12), ('bounce', 32), ('radical', 4)]\n"
     ]
    }
   ],
   "source": [
    "# This is a comment.  \n",
    "# Any line starting with # will be interpreted as a comment\n",
    "\n",
    "# this is a string assigned to a variable\n",
    "greeting = \"hello\"\n",
    "\n",
    "# If enclosed in triple quotes, strings can also be multiline:\n",
    "\n",
    "\"\"\"\n",
    "I'm a multiline\n",
    "string.\n",
    "\"\"\"\n",
    "\n",
    "# let's use a for loop to print it letter by letter\n",
    "for letter in greeting:\n",
    "    print(letter)\n",
    "    \n",
    "# Did you notice the indentation there?  Whitespace matters in Python!\n",
    "\n",
    "# here's a list of integers\n",
    "\n",
    "numbers = [1, 2, 3, 4]\n",
    "\n",
    "# let's add one to each number using a list comprehension\n",
    "# and assign the result to a variable called res\n",
    "# list comprehensions are used widely in Python (they're very Pythonic!)\n",
    "\n",
    "res = [num + 1 for num in numbers]\n",
    "\n",
    "# let's confirm that it worked\n",
    "print(res)\n",
    "\n",
    "# now let's try spicing things up using a conditional to filter out all values greater than or equal to 3...\n",
    "print([num for num in res if not num >= 3])\n",
    "\n",
    "# Python 3.7 introduced \"f-strings\" as a convenient way of formatting strings using templates\n",
    "# For example ...\n",
    "name = \"Josuke\"\n",
    "\n",
    "print(f\"{greeting}, {name}!\")\n",
    "\n",
    "# f-strings are f-ing convenient!\n",
    "\n",
    "\n",
    "# let's look at defining functions in Python..\n",
    "\n",
    "def greet(name):\n",
    "    print(f\"Howdy, {name}!\")\n",
    "\n",
    "# here's how we call it...\n",
    "\n",
    "greet(\"partner\")\n",
    "\n",
    "# let's add a description of the function...\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"\n",
    "    Prints a greeting given some name.\n",
    "    \n",
    "    :param name: the name to be addressed in the greeting\n",
    "    :type name: str\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"Howdy, {name}!\")\n",
    "    \n",
    "# I encourage you to use docstrings!\n",
    "\n",
    "# Python introduced support for optional type hints in v3.5.\n",
    "# You can read more aobut this feature here: https://docs.python.org/3.8/library/typing.html\n",
    "# let's give it a try...\n",
    "def add_six(num: int) -> int:\n",
    "    return num + 6\n",
    "\n",
    "# this should print 13\n",
    "print(add_six(7))\n",
    "\n",
    "# Python also has \"anonymous functions\" (also known as \"lambda\" functions)\n",
    "# take a look at the following code:\n",
    "\n",
    "greet_alt = lambda name: print(f\"Hi, {name}!\")\n",
    "\n",
    "greet_alt(\"Fred\")\n",
    "\n",
    "# lambda functions are often passed to other functions\n",
    "# For example, they can be used to specify how a sequence should be sorted\n",
    "# let's sort a list of pairs by their second element\n",
    "pairs = [(\"bounce\", 32), (\"bighorn\", 12), (\"radical\", 4), (\"analysis\", 7)]\n",
    "# -1 is last thing in some sequence, -2 is the second to last thing in some seq, etc.\n",
    "print(sorted(pairs, key=lambda pair: pair[-1]))\n",
    "\n",
    "# we can sort it by the first element instead\n",
    "# NOTE: python indexing is zero-based\n",
    "print(sorted(pairs, key=lambda pair: pair[0]))\n",
    "\n",
    "# You can learn more about other core data types and their methods here: \n",
    "# https://docs.python.org/3.8/library/stdtypes.html\n",
    "\n",
    "# Because of its extensive standard library, Python is often described as coming with \"batteries included\".  \n",
    "# Take a look at these \"batteries\": https://docs.python.org/3.8/library/\n",
    "\n",
    "# You now know enough to complete this homework assignment (or at least where to look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9833c1ce55cdc8f894b287df328ab677",
     "grade": false,
     "grade_id": "test-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Iterable, List, Tuple, Text, Union\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import spmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "977e8748cd34c9d1bcdec0b84601b983",
     "grade": false,
     "grade_id": "needed-imports",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add needed imports here!\n",
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f9a7e22714cd4819e5c3540627384cd",
     "grade": false,
     "grade_id": "random-seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# An NDArray can either be a numpy array (np.ndarray) or a sparse matrix (spmatrix)\n",
    "NDArray = Union[np.ndarray, spmatrix]\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a90496aa4958e8d071d296eefc9a2bdb",
     "grade": false,
     "grade_id": "cell-f4a4e53967b8f695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment overview\n",
    "\n",
    "In this assignment, you'll use a binomial logistic regression classifier with $n$-gram features to categorize SMS messages as **SPAM** or **NOT SPAM**.  \n",
    "\n",
    "You will not be required to implement logistic regression from scratch.  Instead, you may use the `scikit-learn` implementation.  Be sure to carefully read the comments in the code skeleton provided.  To earn full credit, all tests must pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7c72a4e0f790e0ca25b37d3db6139db",
     "grade": false,
     "grade_id": "md-read-smsspam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `.read_smsspam()`\n",
    "\n",
    "First we'll need data for training and evaluating our classifier.\n",
    "\n",
    "Complete the function below which takes a path to a file (stored under `data` in the docker image) and returns a sequence of (label, text) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7257ac60f5c5b2fcb7413e967cda841",
     "grade": false,
     "grade_id": "code-read-smsspam",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_smsspam(smsspam_path: Text) -> Iterator[Tuple[Text, Text]]:\n",
    "    \"\"\"\n",
    "    Generates (label, text) tuples from the lines in an SMSSpam file.\n",
    "\n",
    "    SMSSpam files contain one message per line. Each line is composed of a label\n",
    "    (ham or spam), a tab character, and the text of the SMS. Here are some\n",
    "    examples:\n",
    "\n",
    "      spam\t85233 FREE>Ringtone!Reply REAL\n",
    "      ham\tI can take you at like noon\n",
    "      ham\tWhere is it. Is there any opening for mca.\n",
    "\n",
    "    :param smsspam_path: The path of an SMSSpam file, formatted as above.\n",
    "    :return: An iterator over (label, text) tuples.\n",
    "    \"\"\"\n",
    "    list_of_tups=[]\n",
    "    with open(smsspam_path, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            parts=line.split('\\t')\n",
    "            list_of_tups.append((parts[0],parts[1][:-1]))\n",
    "    return list_of_tups\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam_train = pd.read_csv(\"data/smsspam/SMSSpamCollection.train\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_spam_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3344, 2)\n"
     ]
    }
   ],
   "source": [
    "print (df_spam_train.shape)# how many rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6688\n"
     ]
    }
   ],
   "source": [
    "print (df_spam_train.size)# how many cells in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ham', 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df_spam_train.columns) #column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham                                                                                                                object\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (df_spam_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "train_labels, train_texts = zip(*train_examples)\n",
    "x = train_labels\n",
    "y = train_texts\n",
    "g = sns.countplot(pd.Series(train_labels))\n",
    "# g = sns.countplot(pd.Series(x(y))\n",
    "\n",
    "g.set_xticklabels(['ham','spam'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "090962f0ecf8cb76ed91165eee0dbdc3",
     "grade": false,
     "grade_id": "md-test-read-smsspam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test `.read_smsspam()` (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd2867872d0662f97fc4f24bb99efb6",
     "grade": true,
     "grade_id": "test-read-smsspam",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# keep a counter here (instead of enumerate) in case the iterator is empty\n",
    "count = 0\n",
    "for example in read_smsspam(\"data/smsspam/SMSSpamCollection.train\"):\n",
    "\n",
    "    # make sure the right shape is returned\n",
    "    assert len(example) == 2\n",
    "    label, text = example\n",
    "\n",
    "    # make sure the label is one of the expected two\n",
    "    assert label in { \"ham\", \"spam\" }\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# You should find exactly 3345 pairs in the training partition of the data\n",
    "assert count == 3345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81129e4c91af384bdc832d4d1b7b75d",
     "grade": false,
     "grade_id": "md-texttofeatures",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `TextToFeatures`\n",
    "\n",
    "Using the provided skeleton, complete the class `TextToFeatures` to transform text (documents) into real-valued features derived from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(string)-> Iterator[Text]:\n",
    "    \n",
    "    # use regex (re.sub) to swap URLs for [URL]\n",
    "    # substitute any chain of numbers with commmas, decimals and dashes to [NUM] token\n",
    "    \n",
    "#     with open(filename, 'r') as file:\n",
    "#         final_list = []\n",
    "\n",
    "    #for line in file:\n",
    "    gone_URL = re.sub(\"\\S*http[s]?:\\S*\", 'URL' , string)\n",
    "    cleanString = re.sub('([^a-zA-Z0-9]+?)',' ', gone_URL )\n",
    "    \n",
    "    # output = re.sub(regular_expression, what_it_should_be_replaced_by, input)\n",
    "    #list_of_words=cleanString .split(\" \") # changing .split() to .split(\" \")\n",
    "    #list_of_words= sorted(list_of_words)\n",
    "    #set_of_words=set(list_of_words)\n",
    "    # set_of_frequencies= { (word,list_of_words.count(word) ) for word in  set_of_words }\n",
    "    #final_list.append ( (   int(contents[0]) , cleanString, set_of_frequencies   )   ) \n",
    "    \n",
    "\n",
    "    return cleanString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Voucher Holder      for you  o claim this weeks offer  at you PC please go to URL Ts Cs apply  To stop texts  txt STOP to 80062'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean(\"Dear Voucher Holder, $$$ for you, o claim this weeks offer, at you PC please go to http://www.e-tlp.co.uk/expressoffer Ts&Cs apply. To stop texts, txt STOP to 80062\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7751ca6573551d429a33f41243cdc2da",
     "grade": false,
     "grade_id": "code-texttofeatures",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TextToFeatures:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an object for converting texts to features.    \n",
    "        \"\"\"\n",
    "        \n",
    "        # HINT: store a you may want to use a sklearn vectorizer.\n",
    "        # vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # experiment with the n-grams and word boundaries\n",
    "\n",
    "        self.vect=CountVectorizer(analyzer = 'word', ngram_range=(1, 3), preprocessor = data_clean) \n",
    "        # self.vect=TfidfVectorizer(analyzer = 'word', ngram_range=(1, 3), preprocessor = data_clean) \n",
    "     \n",
    "        #self.vect= TfidfVectorizer(ngram_range=(1, 3)) # Alternate vectorizer \n",
    "            # Using TFIDF actually reduced the performance as I experimented with the \n",
    "            # n-gram construct\n",
    "\n",
    "    def fit(self, training_texts: Iterable[Text]) -> None:\n",
    "        \"\"\"\n",
    "        Fits (\"trains\") a TextToFeature instance on a collection of documents.\n",
    "        \n",
    "        The provided training texts are analyzed to determine the vocabulary, \n",
    "        i.e., all feature values that the converter will support. \n",
    "        Each such feature value will be associated with a unique integer index \n",
    "        that may later be accessed via the .index() method.\n",
    "\n",
    "        It is up to the implementer exactly what features to produce from a\n",
    "        text, but the features will always include some single words and some\n",
    "        multi-word expressions (e.g., \"need\" and \"to you\").\n",
    "        \n",
    "        \n",
    "        docs = [\n",
    "            \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "            \"The IRS has been trying to reach you.\",\n",
    "            \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "            \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "        ]\n",
    "        \n",
    "        t2f = TextToFeatures()\n",
    "        t2f.fit(docs)\n",
    "\n",
    "        :param training_texts: The training texts.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.vect.fit(training_texts)\n",
    "        \n",
    "        \n",
    "    def index(self, feature: Text) -> Union[None, int]:\n",
    "        \"\"\"\n",
    "        Returns the index in the vocabulary of the given feature value.  \n",
    "        If the features isn't present, return None.\n",
    "\n",
    "        :param feature: A feature\n",
    "        :return: The unique integer index associated with the feature or None if not present.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        vocab = self.vect.get_feature_names()\n",
    "        if( feature in vocab):\n",
    "            return vocab.index(feature)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "\n",
    "    def transform(self, texts: Iterable[Text]) -> NDArray:\n",
    "        \"\"\"\n",
    "        Creates a feature matrix from a sequence of texts.\n",
    "        \n",
    "        docs = [\n",
    "            \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "            \"The IRS has been trying to reach you.\",\n",
    "            \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "            \"I'd like to add you to my professional network on LinkedIn\",\n",
    "        ]\n",
    "        \n",
    "        t2f = TextToFeatures()\n",
    "        t2f.fit(docs)\n",
    "\n",
    "        # this produces a NDArray representing our features for the provided doc\n",
    "        t2f.transform([\"Let's meet at Coyote Joe's at 6.\"])\n",
    "\n",
    "\n",
    "        Each row of the matrix corresponds to one of the input texts. The value\n",
    "        at index j of row i is the value in the ith text of the feature\n",
    "        associated with the unique integer j.\n",
    "\n",
    "        It is up to the implementer what the value of a feature that is present\n",
    "        in a text should be, though a common choice is 1. Features that are\n",
    "        absent from a text will have the value 0.\n",
    "\n",
    "        :param texts: A sequence of texts.\n",
    "        :return: A matrix, with one row of feature values for each text.\n",
    "        \"\"\"\n",
    "        return self.vect.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_texts: List[Text] = [\n",
    "    \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "    \"The IRS has been trying to reach you.\",\n",
    "    \"You won't believe what in this doc.  Click here to find out!\",\n",
    "    \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "    \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "]\n",
    "    \n",
    "t2f = TextToFeatures()\n",
    "\n",
    "t2f.fit(training_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c9606eb97271a658b6e05ec97db13fa",
     "grade": false,
     "grade_id": "md-test-texttofeatures",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test features (5 pts)\n",
    "\n",
    "Let's test the behavior of your implementation of `TextToFeatures`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44a96b5e05f7712556a58cbeaa76fe29",
     "grade": true,
     "grade_id": "test-texttofeatures-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "training_texts: List[Text] = [\n",
    "    \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "    \"The IRS has been trying to reach you.\",\n",
    "    \"You won't believe what in this doc.  Click here to find out!\",\n",
    "    \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "    \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "]\n",
    "    \n",
    "t2f = TextToFeatures()\n",
    "t2f.fit(training_texts)\n",
    "\n",
    "features = t2f.transform([\"Is Bill in your professional network?\"]).todense()\n",
    "# ensure there is one row of features for each sentence\n",
    "assert features.shape[0] == 1\n",
    "# ensure there are nonzero values for some selected unigram and bigram features\n",
    "assert t2f.index(\"reach\") is not None\n",
    "\n",
    "# if a feature wasn't observed during training, it should not have an index\n",
    "assert t2f.index(\"strawberry kangaroos\") is None\n",
    "assert t2f.index(\"Jason Mendoza\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9224d03103ffcae0364463cc832a58ec",
     "grade": true,
     "grade_id": "test-texttofeatures-2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the texts from the training data\n",
    "examples: Iterable[Tuple[str, str]]  = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "training_texts: List[str]            = [text for _, text in examples]\n",
    "\n",
    "# create the feature extractor from the training texts\n",
    "t2f = TextToFeatures()\n",
    "t2f.fit(training_texts)\n",
    "\n",
    "# extract features for some made-up sentences\n",
    "features = t2f.transform([\n",
    "    \"There are some things that I need to send to you.\",\n",
    "    \"Hello!\"\n",
    "]).todense()\n",
    "\n",
    "# make sure there is one row of features for each sentence\n",
    "assert len(features.shape) == 2\n",
    "n_rows, n_cols = features.shape\n",
    "assert n_rows == 2\n",
    "\n",
    "# make sure there are nonzero values for some selected unigram and bigram\n",
    "# features in the first sentence\n",
    "indices = [t2f.index(f) for f in [\"need\", \"to you\"]]\n",
    "assert len(set(indices)) > 1\n",
    "row_indices, col_indices = features[:, indices].nonzero()\n",
    "assert np.all(row_indices == 0)\n",
    "assert len(col_indices) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TextToLabels`\n",
    "Using the provided skeleton, complete the class `TextToLabels` to map class labels (strings) to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fbaab7c6286a32261319404ea3805e9",
     "grade": false,
     "grade_id": "code-texttolabels",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TextToLabels:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an object for converting texts to labels.\n",
    "        \"\"\"\n",
    "        self.le = LabelEncoder()\n",
    "\n",
    "    def fit(self, training_labels: Iterable[Text]) -> None:\n",
    "        \"\"\"\n",
    "        Assigns each distinct label a unique integer.\n",
    "        \n",
    "        \n",
    "        Training labels are analyzed to determine the vocabulary, \n",
    "        i.e., all labels that the converter will support. \n",
    "        Each such label will be associated with a unique integer index \n",
    "        that may later be accessed via the .index() method.\n",
    "\n",
    "        :param training_labels: The training labels.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.le.fit(training_labels)\n",
    "        \n",
    "    def index(self, label: Text) -> Union[None, int]:\n",
    "        \"\"\"Returns the index in the vocabulary of the given label.\n",
    "\n",
    "        :param label: A label\n",
    "        :return: The unique integer index associated with the label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        vocab = list(self.le.classes_)\n",
    "        if( label in vocab):\n",
    "            return vocab.index(label)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def transform(self, labels: Iterable[Text]) -> NDArray:\n",
    "        \"\"\"\n",
    "        Creates a label vector from a sequence of labels.\n",
    "\n",
    "        Each entry in the vector corresponds to one of the input labels. The\n",
    "        value at index j is the unique integer associated with the jth label.\n",
    "\n",
    "        :param labels: A sequence of labels.\n",
    "        :return: A vector, with one entry for each label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return self.le.transform(labels)\n",
    "        \n",
    "        \n",
    "    def __contains__(self, label: Text) -> bool:\n",
    "        \"\"\"\n",
    "        Special \"dunder\" method to check if a label is known to the TextToLabels instance.\n",
    "        \n",
    "        labeler = TextToLabels()\n",
    "        labeler.fit([\"POSITIVE\", \"NEGATIVE\"])\n",
    "\n",
    "        # should be True:\n",
    "        \"POSITIVE\" in labeler \n",
    "        \n",
    "        # should be False:\n",
    "        \"MBOP\" in labeler\n",
    "        \n",
    "        :return: True if the label was seen in the training data; False otherwise\n",
    "        \"\"\"\n",
    "        # NOTE: you do not need to change this if you've implemented .index() correctly!\n",
    "        return False if self.index(label) is None else True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88f44e011390d5de39183a7ca5d80865",
     "grade": false,
     "grade_id": "md-test-texttolabels",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test labels (5pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46a9acdc3680ae11eae0bb7070762735",
     "grade": true,
     "grade_id": "test-texttolabels-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_labels = [\"SPAM\", \"NOT_SPAM\"]\n",
    "lbl_encoder     = TextToLabels()\n",
    "lbl_encoder.fit(training_labels)\n",
    "\n",
    "assert \"SPAM\" in lbl_encoder\n",
    "assert lbl_encoder.index(\"SPAM\") is not None\n",
    "\n",
    "# this label wasn't seen in the training data labels\n",
    "assert \"DISSERTATION\" not in lbl_encoder\n",
    "assert lbl_encoder.index(\"DISSERTATION\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "297f9ee32baa3ab146ebdc9b7f4a79b0",
     "grade": true,
     "grade_id": "test-texttolabels-2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_labels():\n",
    "    # get the texts from the training data\n",
    "    examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    labels = [label for label, _ in examples]\n",
    "\n",
    "    # create the label encoder from the training texts\n",
    "    lbl_encoder = TextToLabels()\n",
    "    lbl_encoder.fit(labels)\n",
    "\n",
    "    # just a simple convenience function to use for testing...\n",
    "    to_labels = lambda labels: lbl_encoder.transform(labels)\n",
    "    \n",
    "    # make sure that some sample labels are encoded as expected\n",
    "    ham_index = lbl_encoder.index(\"ham\")\n",
    "    spam_index = lbl_encoder.index(\"spam\")\n",
    "    assert ham_index != spam_index\n",
    "    assert np.all(\n",
    "        to_labels([\"ham\", \"spam\", \"spam\"]) == [ham_index, spam_index, spam_index]\n",
    "    )\n",
    "\n",
    "test_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3343935439326da0eda803a66ea6bbec",
     "grade": false,
     "grade_id": "cell-12ff0ecbb3bbcf93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# `Classifier`\n",
    "Using the provided skeleton, complete the class `Classifier` which will use `sklearn`'s logistic regression classifier.  You will implement the `train` and `predict` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import NearMiss\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87d7be9c626dd81f9feb533d71c8bbbc",
     "grade": false,
     "grade_id": "cell-b30da2f58a08c088",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes a logistic regression classifier.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        #self.lr = LogisticRegression(penalty='l2')# 89.7% F1 and 97.4% \n",
    "        #self.lr = LogisticRegression(solver='liblinear' )#90.8% F1 and 97.6%\n",
    "        self.lr = LogisticRegression (C=1, penalty='l1', solver='liblinear')\n",
    "        clf= LogisticRegression()\n",
    "        #grid_values = {'penalty': [ 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "        #self.lr = GridSearchCV(clf, param_grid = grid_values,scoring = 'accuracy',error_score='raise')\n",
    "\n",
    "    def train(self, features: NDArray, labels: NDArray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the classifier using the given training examples.\n",
    "\n",
    "        :param features: A feature matrix, where each row represents a text.\n",
    "        Such matrices will typically be generated via TextToFeatures.\n",
    "        :param labels: A label vector, where each entry represents a label.\n",
    "        Such vectors will typically be generated via TextToLabels.\n",
    "        \"\"\"\n",
    "        \n",
    "        #SMOTE\n",
    "        #oversample = SMOTE() # there is class imbalance in training data\n",
    "        #X, y = oversample.fit_resample(features, labels)\n",
    "        #72.3% F1 and 91.7% accuracy on SMSSpam development data\n",
    "        \n",
    "        #RUS\n",
    "        #rus = RandomUnderSampler(random_state=42, replacement=False)# fit predictor and target variable\n",
    "        #X, y = rus.fit_resample(features, labels)\n",
    "        #88.4% F1 and 97.1% accuracy on SMSSpam development data\n",
    "        \n",
    "        #Near miss\n",
    "        #nm = NearMiss()\n",
    "        #x_nm, y_nm = nm.fit_resample(features, labels)\n",
    "        #71.8% F1 and 91.5% accuracy on SMSSpam development data\n",
    "        \n",
    "        #self.lr.fit(X,y)\n",
    "        self.lr.fit(features, labels)\n",
    "        #87.2% F1 and 97.1% accuracy on SMSSpam development data (without class balancing)\n",
    "    \n",
    "    # just an alias for \"train\"\n",
    "    fit = train\n",
    "    \n",
    "    def predict(self, features: NDArray) -> NDArray:\n",
    "        \"\"\"Makes predictions for each of the given examples.\n",
    "\n",
    "        :param features: A feature matrix, where each row represents a text.\n",
    "        Such matrices will typically be generated via TextToFeatures.\n",
    "        :return: A prediction vector, where each entry represents a label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return self.lr.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with some scoring calculations so we can try and tweak:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with different n-gram ranges\n",
    "# for N in range(1,11):\n",
    "    \n",
    "#     # convert training data to bag of words\n",
    "#     cv = CountVectorizer(analyzer = 'word',ngram_range=(1,N), stop_words='english')\n",
    "#     X_train_cv = cv.fit_transform(X_train)\n",
    "#     X_test_cv = cv.transform(X_test)\n",
    "    \n",
    "#     # train model and generate predictions\n",
    "#     clf = MultinomialNB()\n",
    "#     clf.fit(X_train_cv, y_train)\n",
    "#     y_pred = clf.predict(X_test_cv)\n",
    "    \n",
    "#     # compute f-1 score\n",
    "#     score = np.round(f1_score(y_test, y_pred, average='micro'),4)\n",
    "#     print('F-1 score of model with n-gram range of {}: {}'.format((1,N), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1deb43374a951cea20982c9325aa112c",
     "grade": false,
     "grade_id": "md-min-f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Min F1 Score (4pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data =read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "# print(train_data[:2],end=\"\\n\\n\")\n",
    "# labels, texts = zip( *train_data[:2])\n",
    "# print(labels)\n",
    "# print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a9164008cfad7c8bf9d8e1520c697a8",
     "grade": true,
     "grade_id": "test-predictions",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "83.3% F1 and 96.3% accuracy on SMSSpam development data\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "accuracy 96.3% did not exceed 97.0%",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pl/k80fpf9s4f9_3rp8hnpw5x0m0000gq/T/ipykernel_3811/3491385297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mmin_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.89\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.97\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"accuracy {accuracy:.1%} did not exceed {min_accuracy:.1%}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"f1 {f1:.1%} did not exceed {min_f1:.1%}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: accuracy 96.3% did not exceed 97.0%"
     ]
    }
   ],
   "source": [
    "def no_peeking() -> bool:\n",
    "    train_data = set(read_smsspam(\"data/smsspam/SMSSpamCollection.train\"))\n",
    "    dev_data   = set(read_smsspam(\"data/smsspam/SMSSpamCollection.devel\"))\n",
    "    if len(train_data) < 10:\n",
    "        print(\"Something is wrong with the training data\")\n",
    "        return False\n",
    "    if len(dev_data) < 10:\n",
    "        print(\"Something is wrong with the dev data\")\n",
    "        return False\n",
    "    \n",
    "    for dev_ex in dev_data:\n",
    "        if dev_ex in train_data:\n",
    "            print(dev_ex)\n",
    "            print(\"Dev data should not overlap with train data!\")\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def test_prediction() -> Tuple[int, int]:\n",
    "    # get texts and labels from the training data\n",
    "    train_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    train_labels, train_texts = zip(*train_examples)\n",
    "\n",
    "    # get texts and labels from the development data\n",
    "    dev_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.devel\")\n",
    "    dev_labels, dev_texts = zip(*dev_examples)\n",
    "\n",
    "    # fit/\"train\" the feature extractor and label encoder\n",
    "    to_features = TextToFeatures()\n",
    "    to_features.fit(train_texts)\n",
    "    to_labels   = TextToLabels()\n",
    "    to_labels.fit(train_labels)\n",
    "\n",
    "    # train the classifier on the training data\n",
    "    clf = Classifier()\n",
    "    clf.train(to_features.transform(train_texts), to_labels.transform(train_labels))\n",
    "\n",
    "    # make predictions on the development data\n",
    "    predicted_indices = clf.predict(to_features.transform(dev_texts))\n",
    "    assert np.array_equal(predicted_indices, predicted_indices.astype(bool))\n",
    "\n",
    "    # measure performance of predictions\n",
    "    dev_indices   = to_labels.transform(dev_labels)\n",
    "    spam_label    = to_labels.index(\"spam\")\n",
    "    f1            = f1_score(dev_indices, predicted_indices, pos_label=spam_label)\n",
    "    accuracy      = accuracy_score(dev_indices, predicted_indices)\n",
    "\n",
    "    print(f\"\\n{f1:.1%} F1 and {accuracy:.1%} accuracy on SMSSpam development data\")\n",
    "    return f1, accuracy\n",
    "\n",
    "\n",
    "# ensure the train and dev data is well-formed\n",
    "assert no_peeking() is True, \"Problem with train and/or dev data\"\n",
    "\n",
    "# make sure that performance is adequate\n",
    "f1, accuracy = test_prediction()\n",
    "min_f1, min_accuracy = 0.89, 0.97\n",
    "\n",
    "assert accuracy > min_accuracy, f\"accuracy {accuracy:.1%} did not exceed {min_accuracy:.1%}\"\n",
    "assert f1 > min_f1, f\"f1 {f1:.1%} did not exceed {min_f1:.1%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "91.3% F1 and 97.8% accuracy on SMSSpam development data\n"
     ]
    }
   ],
   "source": [
    "def no_peeking() -> bool:\n",
    "    train_data = set(read_smsspam(\"data/smsspam/SMSSpamCollection.train\"))\n",
    "    dev_data   = set(read_smsspam(\"data/smsspam/SMSSpamCollection.devel\"))\n",
    "    if len(train_data) < 10:\n",
    "        print(\"Something is wrong with the training data\")\n",
    "        return False\n",
    "    if len(dev_data) < 10:\n",
    "        print(\"Something is wrong with the dev data\")\n",
    "        return False\n",
    "    \n",
    "    for dev_ex in dev_data:\n",
    "        if dev_ex in train_data:\n",
    "            print(dev_ex)\n",
    "            print(\"Dev data should not overlap with train data!\")\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def test_prediction() -> Tuple[int, int]:\n",
    "    # get texts and labels from the training data\n",
    "    train_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    train_labels, train_texts = zip(*train_examples)\n",
    "\n",
    "    # get texts and labels from the development data\n",
    "    dev_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.test\")\n",
    "    dev_labels, dev_texts = zip(*dev_examples)\n",
    "\n",
    "    # fit/\"train\" the feature extractor and label encoder\n",
    "    to_features = TextToFeatures()\n",
    "    to_features.fit(train_texts)\n",
    "    to_labels   = TextToLabels()\n",
    "    to_labels.fit(train_labels)\n",
    "\n",
    "    # train the classifier on the training data\n",
    "    clf = Classifier()\n",
    "    clf.train(to_features.transform(train_texts), to_labels.transform(train_labels))\n",
    "\n",
    "    # make predictions on the development data\n",
    "    predicted_indices = clf.predict(to_features.transform(dev_texts))\n",
    "    assert np.array_equal(predicted_indices, predicted_indices.astype(bool))\n",
    "\n",
    "    # measure performance of predictions\n",
    "    dev_indices   = to_labels.transform(dev_labels)\n",
    "    spam_label    = to_labels.index(\"spam\")\n",
    "    f1            = f1_score(dev_indices, predicted_indices, pos_label=spam_label)\n",
    "    accuracy      = accuracy_score(dev_indices, predicted_indices)\n",
    "\n",
    "    print(f\"\\n{f1:.1%} F1 and {accuracy:.1%} accuracy on SMSSpam development data\")\n",
    "    return f1, accuracy\n",
    "\n",
    "\n",
    "# ensure the train and dev data is well-formed\n",
    "assert no_peeking() is True, \"Problem with train and/or dev data\"\n",
    "\n",
    "# make sure that performance is adequate\n",
    "f1, accuracy = test_prediction()\n",
    "min_f1, min_accuracy = 0.89, 0.97\n",
    "\n",
    "assert accuracy > min_accuracy, f\"accuracy {accuracy:.1%} did not exceed {min_accuracy:.1%}\"\n",
    "assert f1 > min_f1, f\"f1 {f1:.1%} did not exceed {min_f1:.1%}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9883f350c5ce553fc21e1d243a17e06",
     "grade": false,
     "grade_id": "md-high-f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## High F1 score (2 pts)\n",
    "\n",
    "Adjust your classifier (ex. features, regularization, etc.) as needed to achieve a minimum F1 score of 0.94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90659ac79cdca4a07f3327d87a315d7d",
     "grade": true,
     "grade_id": "test-high-performance",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "83.3% F1 and 96.3% accuracy on SMSSpam development data\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "accuracy 96.3% did not exceed 98.0%",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pl/k80fpf9s4f9_3rp8hnpw5x0m0000gq/T/ipykernel_64984/1719974215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmin_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.94\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.98\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make sure that performance is adequate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"accuracy {accuracy:.1%} did not exceed {min_accuracy:.1%}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"f1 {f1:.1%} did not exceed {min_f1:.1%}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: accuracy 96.3% did not exceed 98.0%"
     ]
    }
   ],
   "source": [
    "f1, accuracy = test_prediction()\n",
    "\n",
    "min_f1, min_accuracy = 0.94, 0.98\n",
    "# make sure that performance is adequate\n",
    "assert accuracy > min_accuracy, f\"accuracy {accuracy:.1%} did not exceed {min_accuracy:.1%}\"\n",
    "assert f1 > min_f1, f\"f1 {f1:.1%} did not exceed {min_f1:.1%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9627450980392157\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
